\documentclass{article}

\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[font=small]{caption}
\usepackage{cite}
\usepackage{graphicx}

\newtheorem{algorithm}{Algorithm}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}

%---------------------------------------------------------------

\title{Analytic combinatorics meets bioinformatics I: applications to
seeding methods}
\author{
\textsc{Guillaume Filion and Eduard Valera Zorita} \\ [1ex]
\normalsize CRG, Barcelona
}
\date{\today}

%---------------------------------------------------------------
%---------------------------------------------------------------


\begin{document}

\maketitle

\begin{abstract}
The abstract will come later.
\end{abstract}


%---------------------------------------------------------------
%---------------------------------------------------------------

\section{Introduction}

High throughput sequencing is changing the face of biology. More data is
of course better, but recently, technical improvements have started to
outpace the progress of algorithms. When the problems are too large,
one has to replace exact algorithms by heuristics that are much faster,
but do not guarantee to return the right result. Good heuristics are all
about understanding the input data. With the right model of the data, we
can calculate the risk of not returning the right answer and adjust the
algorithm to achieve more precision or more speed. When the data is poorly
understood, heuristics may be slow or inefficient for unknown reasons.

A particular area of bioinformatics where heuristics have been in use for
a long time is the field of sequence alignment. Computing the best
alignment between two sequences is carried out by dynamic programming in
time $O(mn)$, where $m$ and $n$ are the sequence lengths. When at least
one of the sequences is long (\textit{e.g.} a genome), this is prohibitive
and heuristics are required.

The most studied heuristics for sequence alignment are called seeding
methods. In a nutshell, the idea is to search short regions of the two
sequences that are very similar and use them as candidates to anchor the
dynamic programming alignment, which is performed only locally
\textit{i.e.} between subsequences of the input. These short regions of
high similarity are called ``seeds''. The benefit of the approach is that
seeds can be found in short time. The risk is that they may not exist,
even if the input sequences are similar.

This strategy was most famously implemented in BLAST for the purpose of
finding local homology between proteins. By working out an approximate
distribution of the identity score for the seeds, the authors were able to
calibrate the BLAST heuristic very accurately in order to gain speed. The
algorithm always performs the minimum amount of work for a desired
confidence level (acceptable false negative rate).

Seeding methods are also heavily used in the mapping problem, where the
original sequence of a read must be found in a reference genome. The
dicovery of indexing methods based on the Burrows-Wheeler transform was
instrumental to develop short read mappers such as BWA and Bowtie. With
such indexes, one can know the number of occurrences of a substring in a
genome in time independent of the genome size. This yields an obvious
seeding strategy whereby all the substrings of the read are queried in the
genome. Here the seeds must have exactly the same sequence in the read and
in the genome.

The heuristic should be calibrated from the probability that a seed of
given length can be found in the read, but this problem has not been fully
solved. The answer depends on the types and frequencies of errors, which
are often context-dependent. Overall, the lack of theoretical framework to
model seeding probabilities is halting progress on this line of research.

Here we solve this problem for abitrary error models using the powerful
theory of analytic combinatorics. This field of research was initiated by
Donlad Knuth in the early days of algorithmics, and later developed by
Robert Sedgewick and Philippe Flajolet. The theory is now mature and used
to tackle may problems outside the analysis of algorithms. However, it
has not yet been realized how useful it can be for bioinformatics.

This document is predominantly written for bioinformaticians and people
with a working knowledge of sequencing technologies and their applications.
Accordingly, the focus will be on explaining the mathematical concepts,
rather than the technological aspects. Also, our goal here is not to push
the boundaries of analytic combinatorics, but to explain how its simplest
concepts are useful to solve common problems in bioinformatics. We have
opted for simplicity, to the detriment of generality and rigor. The
results presented here are only a basic introduction to analytic
combinatorics; the field is currently much more advanced and we refer the
interested to the original literature.

\section{Analytic combinatorics}
\label{sec:anal}

\subsection{Weighted generating functions}
\label{subsec:WGF}

\begin{definition}
\label{def:GF}
Let $\mathcal{A}$ be a set of combinatorial objects characterized by a
size and a weight. The weighted generating function of $\mathcal{A}$ is
defined as

\begin{equation}
\label{eq:GF1}
A(z) = \sum_{a \in A} w(a) z^{|a|},
\end{equation}

\noindent
where $|a|$ and $w(a)$ denote the size and weight of the object $a$,
respectively. This also defines a sequence $(a_k)_{k \geq 0}$ such that 

\begin{equation}
\label{eq:GF2}
A(z) = \sum_{k=0}^\infty a_k z^k.
\end{equation}

By definition $a_k = \sum_{a \in A_k}w(a)$, where $A_k$ is the class of
objects of size $k$. The number $a_k$ is called the total weight of
objects of size $k$.
\end{definition}

\begin{remark}
\label{rem:noweight}
If the weight of every object $a \in \mathcal{A}$ is $1$, then $A(z)$ is a
simple generating function and $a_k$ in expression (\ref{eq:GF2}) is
the number of objects of size $k$.
\end{remark}

Note that in definition \ref{def:GF}, the weight is a property of
combinatorial objects and the total weight is a property of a classes of
ojects. Expressions (\ref{eq:GF1}) and (\ref{eq:GF2}) are equivalent.
Depending on the context, we will use one or the other.

The essence of analytic combinatorics is that some operations on
combinatorial objects correspond to some operations on their generatintg
function. If $A(z)$ and $B(Z)$ are the weighted generating functions of
two mutually exclusive sets $\mathcal{A}$ and $\mathcal{B}$, the weighted
generating function of $\mathcal{A} \cup \mathcal{B}$ is $A(z) + B(z)$, as
appears immediately from expression (\ref{eq:GF1}). Size and weight can be
extended to pairs of objects in $\mathcal{A} \times \mathcal{B}$ by
defining $|(a,b)| = |a| + |b|$ and $w(a,b) = w(a)w(b)$. With this
convention, the weighted generating function of $\mathcal{A} \times
\mathcal{B}$ is $A(z)B(z)$, as shown by expression (\ref{eq:GF1})
once again

\begin{equation*}
A(z)B(z) =
\sum_{a\in \mathcal{A}}w(a)z^{|a|} \sum_{b\in \mathcal{B}}w(b)z^{|b|}
= \sum_{(a,b) \in \mathcal{A} \times \mathcal{B}} w(a)w(b)z^{|a|+|b|}.
\end{equation*}

\begin{example}
\label{ex:simple}
Assume that $\mathcal{A}$ contains a single object $a$ of size $1$ and of
weight $p$. The weighted generating function of $\mathcal{A}$ is $pz$.
The set $\mathcal{A}^2$ contains a single object $(a,a)$ of size $2$ and
weight $p^2$. Its weighted generating function is $p^2z^2 = pz \cdot pz$.
\end{example}

The definition of size and weight can be further extended to any finite
Cartesian product in the same way. The generating function of a cartesian
product then comes as the product of their generating functions.

\begin{example}
\label{ex:sequences}
Following up on example~\ref{ex:simple}, the set $\mathcal{A}^k$ contains
a single object of size $k$ and weight $p^k$, and its weighted generating
function is $p^kz^k$. Since the sets $\mathcal{A}, \mathcal{A}^2,
\mathcal{A}^3,\ldots$ are mutually exclusive, the weighted generating
function of their union is

\begin{equation*}
pz + (pz)^2 + (pz)^3 \ldots
\end{equation*}

For any given $k$, notice that $(1-pz) \big(pz + (pz)^2 + \ldots + (pz)^k
\big) = pz-(pz)^{k+1}$.  If $|z| < 1/p$, the term $(pz)^{k+1}$ vanishes as
$k$ increases. So the weighted generating function is defined for $|z| <
1/p$ and is equal to

\begin{equation*}
pz + (pz)^2 + (pz)^3 \ldots = \frac{pz}{1-pz}.
\end{equation*}
\end{example}

Example~\ref{ex:sequences} can be generalized. For any set $\mathcal{A}$,
objects of $\mathcal{A}^+ = \cup_{k=1}^\infty\mathcal{A}^k$ are called
nonempty (finite) sequences of objects of $\mathcal{A}$. By defining
$\mathcal{A}^0$ as the set containg only $\varepsilon$, the ``empty''
object of size 0 and weight 1, we can also define $\mathcal{A}^* =
\cup_{k=0}^\infty\mathcal{A}^k$ as the set of sequences of objects of
$\mathcal{A}$.

\begin{proposition}
\label{th:sequences}
Let $\mathcal{A}$ be a set with weighted generating function $A(z)$. The
generating functions of $\mathcal{A}^+$ and $\mathcal{A}^*$ are defined
for $|A(z)| < 1$ and are respectively equal to

\begin{equation*}
\begin{split}
\frac{A(z)}{1-A(z)}&\text{, and} \\
\frac{1}{1-A(z)}&.
\end{split}
\end{equation*}
\end{proposition}

\begin{proof}
For $k \geq 1$, the generating function of $\mathcal{A}^k$ is $A(z)^k$ and
since the sets are mutually exclusive, the weighted generating function of
their union $\mathcal{A}^+$ is $A(z) + A(z)^2 + \ldots = A(z) / (1-A(z))$,
provided $|A(z)| < 1$.

The generating function of $\mathcal{A}^0$ is $1$ so the weighted
generating function of $\mathcal{A}^*$ is $1 + A(z) + A(z)^2 + \ldots =
1 / (1-A(z))$, provided $|A(z)| < 1$.
\end{proof}

\begin{remark}
These expressions are not defined for $A(z) = 1$, \textit{i.e.} when
$\mathcal{A}$ contains only the empty object. In other words, one cannot
construct sequences of empty ojects.
\end{remark}

From here on, we will not state the conditions of definition of the
generating functions. We will simply assume that $|z|$ is lower than the
radius of convergence of the given expression.

Let us illustrate how to count with generating functions. Following
remark~\ref{rem:noweight}, if the weights of all the objects are equal to
$1$, then the coefficient of $z^k$ in (\ref{eq:GF2}) is the number of
objects of size $k$.

\begin{example}
\label{ex:noweight}
Let $\mathcal{A}$ and $\mathcal{B}$ be alphabets with only one symbol
each. Say $\mathcal{A} = \{a\}$ and $\mathcal{B} = \{b\}$. Each symbol
has weight $1$, so the simple generating function of each alphabet is $z$.
The generating function of $\mathcal{A} \cup \mathcal{B}$, the alphabet
with both symbols is $z+z = 2z$. This means that $\mathcal{A} \cup
\mathcal{B}$ contains two objects of size $1$ and nothing else.

Let us now combine the symbols into sequences and count them. By
proposition~\ref{th:sequences}, the generating function of sequences of
letters from $\mathcal{A} \cup \mathcal{B}$ is

\begin{equation*}
\frac{1}{1-2z} = 1 + 2z + (2z)^2 + (2z)^3 + \ldots
\end{equation*}

The coefficient of $z^k$ in this expression is $2^k$. In other words,
there are $2^k$ sequences of size $k$ made of the two symbols $a$ and $b$.
\end{example}

If some objects are more frequent or more common than others, we can give
them different weights. Let us revisit the previous example with a slight
modification.

\begin{example}
\label{ex:wweights}
Assume once again that $\mathcal{A} = \{a\}$ and $\mathcal{B} = \{b\}$,
but this time $a$ has frequency $1/3$ and $b$ has frequency $2/3$. The
weighted generating function of $\mathcal{A}$ is $z/3$ and that of
$\mathcal{B}$ is $2z/3$. The generating function of $\mathcal{A} \cup
\mathcal{B}$ is $z/3 + 2z/3 = z$. This does not say how many objects are
in $\mathcal{A} \cup \mathcal{B}$ but it says that there only objects of
size $1$ and that their total weight is $1$.

As in example~\ref{ex:noweight}, let us combine the symbols into
sequences. The generating function of sequences of letters from
$\mathcal{A} \cup \mathcal{B}$ is

\begin{equation*}
\frac{1}{1-z} = 1 + z + z^2 + z^3 + \ldots
\end{equation*}

For every $k \geq 0$, the coefficient of $z^k$ in this expression is $1$,
so there are sequences of all sizes. This does not give the number of
sequences of each size, but it says that their total weight is $1$.

This may seem useless, but let us now evaluate the probatility that a
sequence does not contain any $b$. In that case, it is a sequence of
elements of $\mathcal{A}$, of which the weighted generating function is

\begin{equation*}
\frac{1}{1-z/3} = 1 + z/3 + (z/3)^2 + (z/3)^3 + \ldots
\end{equation*}

The coefficient of $z^k$ is $1/3^k$ so sequences of size $k$ that contain
no $b$ have a total weight equal to $1/3^k$. Since the total weight of
sequences of size $k$ is $1$, the total weight of sequences that do not
contain any $b$ is $1/3^k \big/ 1 = 1/3^k$.
\end{example}

In example~\ref{ex:wweights}, the weighted generating function of the
sequence $aaaba$ is $z/3 \times z/3 \times z/3 \times 2z/3 \times z/3 =
2z^5/243$, which is another way of saying that $aaaba$ has size $5$ and
weight $2/243$. Observe that if the symbols are chosen independently of
each other, $2/243$ is the probability that a sequence of size $5$ is
equal to $aaaba$. This is a general feature of weights. In the
applications below, they will always be equal to the probability
of occurrence of the objects they mark.

The coefficients of weighted generating functions expressed as in
(\ref{eq:GF2}) thus represent the probabilities of occurrence of some
objects of interest. This observation motivates the search for
their weighted generating function.



%%%%%%%%%%%%%%%%% Transfer matrices %%%%%%%%%%%%%%%%%

\subsection{Sequences and transfer matrices}

In many combinatorial applications, one needs to count the sequences where
a pattern does or does not occur. A convenient way to find the weighted
generating functions of such sequences is to use transfer matrices in
order to encode the allowed or disallowed patterns. We will illustrate
the process informally with an example from biology, before introducing
the formal definitions.

DNA methylation can only occur on the dinucleotide \texttt{CG}s in many
animal genomes. Because of this property, it is interesting to count the
sequences that have no \texttt{CG}. Such a sequence is a walk on the
graph with restricted transitions shown in figure~\ref{fig:CG_transtions}.

\begin{figure}[h]
\centering
\includegraphics[scale=0.9]{CG_transitions.pdf}
\caption{\textbf{Graph with restricted transitions}.
A sequence without \texttt{CG} can be seen as a walk on the graph above.
All the transitions are allowed, except \texttt{C} to \texttt{G}.}
\label{fig:CG_transtions}
\end{figure}

Arranging the nodes in alphabetical order, the adjacency matrix of the
directed graph is

\begin{equation*}
M = \left[
\begin{matrix}
1 & 1 & 1 & 1 \\
1 & 1 & 0 & 1 \\
1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1
\end{matrix}
\right].
\end{equation*}

The entry of the matrix $M^n$ at position $(i,j)$ corresponds to the
number of paths on this graph that start with nucleotide $i$, end with
nucleotide $j$ and contain $n$ steps. So a way to count sequences without
\texttt{CG} is to compute the powers of the adjacency matrix $M$.

Instead of just their numbers, we can go one step furhter and get the
weighted generating functions of those sequences. Replacing the $1$s in the
adjacency matrix by the weighted generating functions of the objects they
represent, we obtain what is called the transfer matrix of the sequence.

This background in mind, we now introduce transfer matrices on the problem
at hand to find the weighted generating function of sequences without
\texttt{CG}.  Assume that \texttt{G}s and \texttt{G}s both occur with
frequency $p/2$ and that \texttt{A}s and \texttt{T}s occur with frequency
$q/2$, where $q = 1-p$. With obvious notations we see that $C(z) = G(z) =
pz/2$ and that $A(z) = T(z) = qz/2$.

\begin{definition}
\label{def:transfermat}
Let $(\mathcal{A}_i)_{1 \leq i \leq k}$ be sets of combinatorial objects,
and let $A_i(z)$ be the weighted generating functions of $\mathcal{A}_i$.
The entry $(i,j)$ of the $k\times n$ transfer matrix is equal to $A_j(z)$
if an object of $\mathcal{A}_i$ can be followed by an object of
$\mathcal{A}_j$, and $0$ otherwise.
\end{definition}

\begin{example}
\label{ex:CGmat}
Ordering the weighted generating functions of nucleotides alphabetically
as $(A(z), C(z), G(z), T(z))$, the transfer matrix of sequences without
\texttt{CG} can be written as

\begin{equation}
\label{eq:Mz_CG}
M(z) = \left[
\begin{matrix}
A(z) & C(z) & G(Z) & T(z) \\
A(z) & C(z) &  0   & T(z) \\
A(z) & C(z) & G(Z) & T(z) \\
A(z) & C(z) & G(Z) & T(z)
\end{matrix}
\right] = z/2 \left[
\begin{matrix}
q & p & p & q \\
q & p & 0 & q \\
q & p & p & q \\
q & p & p & q
\end{matrix}
\right].
\end{equation}
\end{example}


The following two propositions show why transfer matrices are useful to
find the weighted generating function of combinatorial sequences.

\begin{proposition}
\label{th:transfermatrices}
Let $(\mathcal{A}_i)_{1 \leq i \leq m}$ be sets of combinatorial objects
and let $A_i(z)$ be the weighted generating function of $\mathcal{A}_i$.
Let $M(z)$ be a square transfer matrix. The weighted generating function
of a sequence of $n+1$ items starting with an object from $\mathcal{A}_i$
and ending with an object from $\mathcal{A}_j$ is

\begin{equation}
\label{eq:mznij}
A_i(z) \cdot \left( M(z)^n \right)_{i,j}.
\end{equation}

It follows that the the weighted generating function of sequences of items
starting with an object from $\mathcal{A}_i$ and ending with an object
from $\mathcal{A}_j$ is

\begin{equation}
\label{eq:I-Mz}
A_i(z) \cdot \left( I - M(z) \right)^{-1}_{i,j},
\end{equation}

\noindent
provided the eigenvalues of $M(z)$ all have modulus less than $1$.
\end{proposition}

\begin{proof}
We proceed by recurrence. For $n = 0$, the sequences have only one item.
Expression (\ref{eq:mznij}) is equal to $A_i(z)$ if $i = j$ and $0$
otherwise, which is the generating function of sequences of one item
starting with an object from $\mathcal{A}_i$ and ending with an object
from $\mathcal{A}_j$.

Assume that (\ref{eq:mznij}) holds for $n \geq 0$. A sequence of $n+2$
items starting with an object from $\mathcal{A}_i$ and ending with an
object from $\mathcal{A}_j$ is a sequence of $n+1$ items starting with an
object from $\mathcal{A}_i$ and ending with an object from any
$\mathcal{A}_k$, followed by an object from $\mathcal{A}_j$. Using the
recurrence hypothesis and the fact that an object from $\mathcal{A}_k$ can
be followed by an object from $\mathcal{A}_j$ if and only if $M(z)_{k,j}
\neq 0$, we obtain the weighted generating function as

\begin{equation*}
\sum_{k = 1}^m A_i(z)\left( M(z)^n \right)_{i,k} M(z)_{k,j} 
 = A_i(z) \left( M(z)^{n+1} \right)_{i,j}.
\end{equation*}

To prove (\ref{eq:I-Mz}), observe that the weighted generating function of
sequences of items starting with an object from $\mathcal{A}_i$ and ending
with an object from $\mathcal{A}_j$ is

\begin{equation*}
\sum_{n=0}^\infty A_i(z) \cdot \left(M(z)^n \right)_{i,j} =
 A_i(z) \cdot \left( \sum_{n=0}^\infty M(z)^n\right)_{i,j} .
\end{equation*}

Now observe that $(I-M(z)) \cdot (I+M(z)+M(z)^2+ \ldots + M(z)^n) =
I-M(z)^{n+1}$, so if all the eigenvalues of $M(z)$ have modulus less than
$1$, the right hand size converges to $I$ as $n$ goes to infinity, which
proves (\ref{eq:I-Mz}).
\end{proof}

\begin{remark}
When the forbidden transitions involve more than two items (\textit{e.g.}
sequences of $\{a,b\}$ without $baa$), the transfer matrix can be modified
to...
\end{remark}

\begin{example}
\label{ex:CGmat2}
Continuing example~\ref{ex:CGmat}, the weighted generating function of
sequences without \texttt{CG} that start with a \texttt{C} and end with a
\texttt{G} is

\begin{equation*}
C(z) \cdot (I-M(z))^{-1}_{2,3}.
\end{equation*}

All the entries of $M(z)$ are less than $1$ for $|z| < 1$ and $M_*(z)$,
the inverse of $I-M(z)$, is found to be equal to 

\begin{equation*}
\frac{1}{\lambda(z)} \left[
\begin{matrix}
(pz)^2+2qz+4   & 2pz        & pz(pz-2)   & 2qz                \\
-pqz^2+2qz     & -2(1+q)z+4 & 2pqz^2     & -pqz^2+2qz         \\
2qz            & 2pz        & -2(1+q)+4  & 2qz                \\
2qz            & 2pz        & pz(1-pz)   & (pz)^2 - 2(p+1) +4
\end{matrix}
\right]
\end{equation*}

\noindent
where $\lambda(z) = (pz)^2 - 4z + 4$ is the determinant of $I-M(z)$. Now
picking the entry at coordinates $(2,3)$, we find that the weighted
generating function is

\begin{equation*}
pz/2\frac{2pqz^2}{(pz)^2 - 4z + 4}
= \frac{p^2qz^3}{(pz)^2 - 4z + 4}.
\end{equation*}
\end{example}

We can also find the weighted generating function of all sequences that do
not contain \texttt{CG} by summing over all possible objects at the
beginning and at the end of the sequence. This is equivalent to computing

\begin{proposition}
\label{th:TM2WGF}
The weighted generating function of all possible sequences described by
the transfer matrix $M(z)$ is 

\begin{equation}
1 + U(z) \cdot (I-M(z))^{-1} \cdot V,
\end{equation}

\noindent
where $U(z)$ is the row vector such the $i$-th element is equal to
$A_i(z)$ if the sequence can start with an object from $\mathcal{A}_i$ and
$0$ otherwise, and $V$ is the column vector such that the $j$-th element
is equal to $1$ if the sequence end with an object from $\mathcal{A}_j$
and $0$ otherwise.
\end{proposition}

\begin{proof}
Applying (\ref{eq:I-Mz}) and summing for all possible start and end cases
gives $U(z) \cdot (I-M(z))^{-1} \cdot V$. We need to add $1$ to account
for the empty sequence.
\end{proof}

\begin{example}
Continuing example~\ref{ex:CGmat2}, sequences without \texttt{CG} may
start with all the nucleotides, so $U(z)$ is the row vector $(A(z), C(z),
G(z), T(z))$. Likewise, they may end with all the nucleotides, so $V$ is
the column vector $(1,1,1,1)$. The weighted generating function of all
possible sequences (including the empty one) without \texttt{CG} is

\begin{equation}
\label{eq:WGFnoCG}
F(z) = \frac{4}{4-4z+(pz)^2}.
\end{equation}
\end{example}

Proposition~\ref{th:transfermatrices} allows us to construct
elaborate weighted generating functions. By expression (\ref{eq:GF1}) from
the definition, the coefficient of $z^k$ in the Taylor expansion of
(\ref{eq:WGFnoCG}) is the sum of the weights of all the sequences of size
$k$ that contain no \texttt{CG}. Due to our normalization, this is also
the probability that a sequence of size $k$ contains no \texttt{CG}.
It would be very useful if we could extract those coefficients from
(\ref{eq:WGFnoCG}) directly. The next section will give a generic method
to do so.



%%%%%%%%%%%%% The crown jewel proposition %%%%%%%%%%%%%

\subsection{Asymptotic estimates}

It is not always possible to extract the exact coefficients of a
generating function, but one of the crown jewels of analytic combinatorics
is that we can very accurately approximate them.

\begin{proposition}
\label{th:ass}
If a weighted generating function $F(z)$ is the ratio of two polynomials
$P(z)/Q(z)$, and the roots of $Q$ are simple, then the coefficient of
$z^k$ in its series expansion is asymptotically equivalent to

\begin{equation}
\label{eq:ass}
-\frac{P(z_1)}{Q'(z_1)}\frac{1}{z_1^{k+1}},
\end{equation}

\noindent
where $z_1$ is the root of smallest modulus of $Q$,
and $Q'$ is the derivative of $Q$.
\end{proposition}

The roots of $Q$ are called the ``singularities'' of the weighted
generating function $F$. They are values where the function is not
defined. When they correspond to simple roots of $Q$, they also referred
to as ``simples poles'' of $A$.

Proposition~\ref{th:ass} says that the asymptotic growth of the
coefficients of the series expansion of $F(z)$ is dictated by the
singularity of smallest modulus, also known as the ``dominant
singularity'' of $F$. We will first state a lemma that will be
important to improve the asymptotic approximation of the coefficients.

\begin{lemma}
\label{lemma:poles}
For $|z| < a$ we have

\begin{equation}
\label{eq:poles}
\frac{1}{1-z/a} = \sum_{k=0}^\infty \frac{z^k}{a^k}.
\end{equation}
\end{lemma}

\begin{proof}
Proceed as in example~\ref{ex:sequences}, replacing $p$ by $1/a$.
\end{proof}

We now prove proposition~\ref{th:ass}.

\begin{proof}
Let $z_1, z_2, \ldots, z_n$ be the complex roots of $Q$ sorted by
increasing order of modulus. It is well known that there exists complex
numbers $s_j$ such that $P(z)/Q(z)$ can be written as

\begin{equation}
\sum_{j=1}^n \frac{s_j}{z-z_j} =
\sum_{j=1}^n \frac{s_j/z_j}{1-z/z_j}.
\end{equation}

Here we assumed without loss of generality that the degree of $P$ is lower
than the degree of $Q$. If this is not the case, the decomposition above
also contains a polynomial whose coefficients are eventually null and
which do not affect the asymptotics. Using lemma~\ref{lemma:poles}, we see
that the coefficient of $z^k$ in the series expansion of $A(z)$ is equal
to

\begin{equation}
\label{eq:fullass}
-\sum_{j=1}^n \frac{s_j}{z_j^{k+1}}.
\end{equation}

Since $z_1$ is the root with smallest modulus, the sum is asymptotically
equivalent to

\begin{equation*}
-\frac{s_1}{z_1^{k+1}}.
\end{equation*}

To find the value of $s_1$, we factorize $Q(z)$ as
$(z-z_1)Q_1(z)$, which is possible because $z_1$ is a root of $Q$,
and we write

\begin{equation*}
\frac{P(z)}{Q(z)} =
\frac{P(z)}{(z-z_1)Q_1(z)} = \frac{s_1}{z-z_1} +
\varepsilon(z).
\end{equation*}

Multiplying both sides by $(z-z_1)$ and setting $z = z_1$ we obtain
the expression

\begin{equation*}
\frac{P(z_1)}{Q_1(z_1)} = s_1.
\end{equation*}

Differentiating $Q(z) = (z-z_1)Q_1(z)$ shows that $Q'(z_1) =
Q_1(z_1)$, and thus $s_1 = P(z_1) / Q'(z_1)$, which concludes the proof.
\end{proof}

\begin{remark}
Expression (\ref{eq:fullass}) is not an approximation, it is the exact
value of the coefficient. By keeping more than one leading term, we can
obtain more accurate estimates, and by keeping all the terms we obtain the
exact number.
\end{remark}

\begin{remark}
The convergence to the asymptotic estimate is exponential. To see this,
divide the exact expression (\ref{eq:fullass}) by its leading term
$-s_1/z_1^{k+1}$ and obtain

\begin{equation*}
\frac{-\sum_{j=1}^n s_j/z_j^{k+1}}{-s_1/z_1^{k+1}} = 1 + \sum_{j=2}^n
\frac{s_j}{s_1} \left( \frac{z_1}{z_j} \right)^{k+1}.
\end{equation*}

Since $z_1 < z_j$ for $2 \leq j \leq n$, the error terms are
$O(|z_1/z_2|^k)$ and they decrease exponentially fast as $k$ increases.
\end{remark}

\begin{remark}
For proposition~\ref{th:ass} to hold, only $z_1$ must be a simple pole. If
this is not the case, the asymptotics growth involves a polynomial term of
the variable $k$. The proposition was stated with this restrictive
condition because all the cases discussed here have only simple poles.
\end{remark}

\begin{example}
Recall from example~\ref{ex:CGmat2} that the weighted generating function
of sequences without \texttt{CG} is

\begin{equation*}
F(z) = \frac{4z-(pz)^2}{4-4z+(pz)^2}.
\end{equation*}

Here $Q(z) = 4-4z+(pz)^2$ has two distinct roots, $z_1 =
2(1-\sqrt{1-p^2})/p^2$ and $z_2 = 2(1+\sqrt{1-p^2})/p^2$. Since $Q'(z) =
2p^2z-4$, the coefficient of $z^k$ is the Taylor expansion of $F(z)$ is
asymptotically equivalent to

\begin{equation*}
\begin{split}
-\frac{P(z_1)}{Q'(z_1)}\frac{1}{z_1^{k+1}} &=
\frac{1}{\sqrt{1-p^2}}
\left( \frac{p^2/2}{1-\sqrt{1-p^2}} \right)^{k+1} \\
&= \frac{1}{\sqrt{1-p^2}} \left(\frac{1+\sqrt{1-p^2}}{2} \right)^{k+1}.
\end{split}
\end{equation*}

In this case we can also obtain the exact answer by using the second root.
The probability that a sequence of size $k$ contains no \texttt{CG} is
exactly equal to

\begin{equation*}
\begin{split}
-\frac{P(z_1)}{Q'(z_1)}\frac{1}{z_1^{k+1}}
&-\frac{P(z_2)}{Q'(z_2)}\frac{1}{z_2^{k+1}} \\
&=
\frac{1}{\sqrt{1-p^2}} \left[
\left( \frac{p^2/2}{1-\sqrt{1-p^2}} \right)^{k+1}
- \left( \frac{p^2/2}{1+\sqrt{1-p^2}} \right)^{k+1}\right] \\
&= \frac{1}{\sqrt{1-p^2}} \left[
\left(\frac{1+\sqrt{1-p^2}}{2} \right)^{k+1} -
\left(\frac{1-\sqrt{1-p^2}}{2} \right)^{k+1} \right].
\end{split}
\end{equation*}

In case all the nucleotides have the same frequency, $p=1/2$ and the
probability is approximately equal to $(0.9330127^{k+1} - 0.0669873^{k+1})
/ 1.154701$. From $k=5$, the second term is more than one million times
smaller than the first, which shows how fast it can be neglected.
\end{example}

Things do not always turn out that simple, but this example illustrates
how analytic combinatorics can offer simple, yet not intuitive solutions.
Actually, it is not clear how one may come to the exact solution with
another approach. This example also illustrates how close the approximate
solution typically is to the exact one.

The purpose of this example is only to expose the analytic combinatorics
approach, which we summarize as follows: $(i)$ define simple objects
associated to simple generating functions, $(ii)$ combine these objects
into more complex structures, $(iii)$ translate those combinations into
more complex generating functions, and $(iv)$ use analytic transfer
theorems to extract coefficients asymptotics.










%%%%%%%%%%%%% Seeding problem begins %%%%%%%%%%%%%

\section{Exact seeding}

From the eperimental point of view, a sequencing read is the result of an
assay on some molecule of a nucleic acid. The output of the assay is the
decoded sequence of monomers that compose the molecule. From the formal
point of view, a read is a finite sequence of symbols.

The focus here is not the nucleotide sequence \textit{per se}, but whether
the symbols are correct. We picture a read as a sequence of symbols
representing the different sequencing error, namely substitutions,
deletions and insertions, plus a symbol for no error.
Figure~\ref{fig:sketchseed} shows the structure of reads for the seeding
problem.

\begin{figure}[h]
\centering
\includegraphics[scale=0.88]{sketch_seeding.pdf}
\caption{\textbf{Structure of reads}. Here we consider sequencing reads
that can have any type of error (insertions, deletions or substitutions).
The reads have size $k$, and the errors are represented as grey squares. A
read is composed of error-free intervals and error-only intervals. Note
that a deletion is an error-only interval of size $0$, so two error-free
intervals can be contiguous (between position $3$ and $4$ in this
example). However error-free intervals have size at least $1$, so two
error-only intervals cannot be contiguous.}
\label{fig:sketchseed}
\end{figure}

Error-free stretches are particularly important because they faithfully
represent the molecule that was sequenced. If they are long, it is
relatively easy to identify the molecule based on the decoded sequence
because the information content is high, but if they are short, it usually
proves more difficult. For instance, modern mapping algorithms are based
on exact searches, using either hash tables or indexes based on the
Burrows-Wheeler transform, so error-free stretches directly influence the
performance of the alrogithm.

In what follows, the feature of interest is the size of the longest
error-free stretch. To facilitate the discussion, we need to introduce
some terms that will be used throughout.

\begin{definition}
\label{def:error-free-interval}
An error-free interval is a nonempty sequence of correct calls that cannot
be extended left or right.
\end{definition}

In other words, an error-free interval contains no error, and it is
flanked by either an error, or by the end of the read. It is important to
highlight that error-free intervals should really be called ``maximal
error-free intervals''. We dropped ``maximal'' for simplicity because we
have no use for non maximal error-free intervals. In the read shown in
figure~\ref{fig:sketchseed}, the leftmost error-free interval has size
$3$, the next has size $1$, the next has size $3$ and the next has size
$4$.

\begin{definition}
\label{def:seed}
An exact $d$-seed is an error-free interval of size at least $d$.
\end{definition}

In what follows, we will refer to a $d$-seed as simply a ``seed''
whenever the value of $d$ is clear from the context or irrelevant.

Our goal here is to estimate the probability that a read contains a seed.
This obviously depends on the size of the read and on the error rate, but
also on the types of errors. Below we develop a general approach to answer
this question building on the tools developed in
section~\ref{sec:anal}.

The strategy is to first exhibit the weighted generating functions of
reads that contain no seed and then use proposition~\ref{th:ass} to
approximate their probability of occurrence.

Observe that a read is a sequence of error-free intervals, interspersed
with errors. This observation motivates us to use transfer matrices to
express the weighted generating function of reads in terms of $F(z)$, the
weighted generating function of error-free intervals. With an expression
where $F(z)$ appears explicitly, we can then replace it by $F_d(z)$, the
weighted generating function of error-free intervals of size smaller than
$d$. This the corresponds to sequences of ``small'' error-free intervals
interspersed with errors, \textit{i.e.} to reads without seed.

To introduce the concepts progressively, we first describe simplified
models where some types of errors are disallowed. We then describe the
more complex models.





%%%%%%%%%%%%%%%%%% Substitutions only %%%%%%%%%%%%%%%%%%%

\subsection{Substitutions only}
\label{sec:substitutions}

One of the simplest and yet useful models is to assume that errors consist
of substitutions only, and that they occur with the same probability $p$
for every nucleotide. This describes reasonably well the error model of
the Illumina platforms (where $p$ is around $0.01$).
Figure~\ref{fig:subonly} shows the transition probabilities between
correct nucleotides and error-free nucleotides.

\begin{figure}[h]
\centering
\includegraphics[scale=0.9]{substitutions_only.pdf}
\caption{\textbf{Substitutions only}. 
The substitution rate $p$ is assumed to be constant throughout the read.
Every decoded nucleotide is correct with probability $q = 1-p$.}
\label{fig:subonly}
\end{figure}

With these assumptions, the weighted generating function of mismatches is
$pz$ and that of correct call is $qz$, where $q=1-p$. Since 
error-free intervals are nonempty sequences of correct calls, their
weighted generating function is simply

\begin{equation}
\label{eq:Fsub}
F(z) = qz + (qz)^2 + (qz)^3 + \ldots = \frac{qz}{1-qz}.
\end{equation}

An error-free interval cannot follow another error-free interval,
otherwise one of them could be extended. So an error-free interval must be
followed by a substitution. On the other hand, a substitution can be
followed by either an error-free interval or another substitution. So the
transfer matrix for the states ``match'' and ``substitution'' is

\begin{equation*}
M(z) = \left(
\begin{matrix}
0    & pz \\
F(z) & pz
\end{matrix}
\right).
\end{equation*}

To find the weighted generating function of reads from
proposition~\ref{th:TM2WGF}, we need to find the inverse of $I-M(z)$.
Since $M(z)$ is a $2 \times 2$ matrix, this is straightforward and we
obtain

\begin{equation*}
M_*(z) = (I-M(z))^{-1}=
\frac{1}{\lambda(z)}
\left(
\begin{matrix}
1-pz & pz   \\
F(z) & 1
\end{matrix}
\right)
\end{equation*}

\noindent
where $\lambda(z) = 1-pz(1+F(z))$ is the determinant of $I-M(z)$. Applying
proposition~\ref{th:TM2WGF} with $U(z)$ equal to the row vector $(F(z),
pz)$ and $V$ the column vector equal to $(1,1)$, the weighted generating
function of reads is

\begin{equation}
\label{eq:Ssub}
R(z) = 1 + U(z) \cdot M_*(z) \cdot V = 
\frac{1+F(z)}{1-pz(1+F(z))} = \frac{1}{1-z}.
\end{equation}

Since $1/(1-z) = 1+z+z^2 + \ldots$, this means that the total weight of
reads of size $k$ is equal to $1$ for every finite $k$. This is convenient
because the probability that a read is seedless is the total weight of
seedless reads divided by the total weight of reads, which in this case is
simply equal to the total weight of seedless reads.

To find the weighted generating function of seedless reads, we need to
limit error-free intervals to a maximum size of $d-1$, \textit{i.e.} to
replace $F(z)$ by its truncation $F_d(z) = qz + (qz)^2 + \ldots
+ (qz)^{d-1}$. We obtain

\begin{equation}
\label{eq:Sp}
S(z) = \frac{1+F_d(z)}{1-pz\big( 1+F_d(z) \big)} =
\frac{1+qz + \ldots + (qz)^{d-1}}{1-pz \big(1+qz + \ldots +
(qz)^{d-1} \big)}.
\end{equation}

The task is now to extract the coefficient of $z^k$ in the series
expansion of expression (\ref{eq:Sp}). Instead of the exact solution, we
look for an asymptotic estimate using proposition~\ref{th:ass}. For this,
we need to find the singularities of $S(z)$.

To higlight some general features of the problem, we start with a concrete
case. The left panel of Figure~\ref{fig:plotQ} shows the values of the
denominator of $S(x)$ with $p=0.1$ and $d=17$ for real $x$ around $0$. $S$
has one real root greater than $1$.  The remaining singularities of $S$
are complex and they seem to be evenly spaced on the same circle, as can
be seen on the right panel of Figure~\ref{fig:plotQ}.  This is only a
visual impression.  In fact the singularities are not exactly on the same
circle and their rotation angles are not exactly regular.

\begin{figure}[h]
\centering
\includegraphics[scale=0.4]{singularityS.pdf}
\caption{\textbf{Singularities of $S$}. $Q(z)$ denotes the
denominator of $S(z)$ from expression (\ref{eq:Sp}) with $p=0.01$ and
$d=17$. \textit{Left}: The value of $Q(z)$ is represented for $z$ real by
the bold line. \textit{Right}: The value of $|1/Q(z)|$ is represented for
$z$ complex by the heat map on the complex plane. Darker pixels correspond
to higher values. Sixteen singularities of $S$ lie close to a circle. The
remaining seventeenth is the one shown on the left panel. It is the
dominant singularity because it is the closest to the origin.}
\label{fig:plotQ}
\end{figure}

It is fortunate that the dominant root of $S$ is a real number because we
can use efficient numerical methods to approximate it (\textit{e.g.}
bisection or the Newton-Raphson method). The following proposition shows
that this is no accident: the dominant singularity of $S$ is always a real
positive number greater than $1$.

\begin{proposition}
\label{th:roots}
$S$ as expressed in (\ref{eq:Sp}) has exactly one positive real
singularity. This is the dominant singularity and it is greater than $1$.
\end{proposition}

\begin{proof}
Write $S(z) = P(z)/Q(z)$ and search the roots of $Q$. First we show that
$Q$ has no real root in the interval $(0,1)$. For a real number $x$ such
that $0\leq x \leq 1$, we have $1+qx+\ldots+(qx)^{d-1} < 1/p$, so $Q(x) >
0$.

Second, we show that $Q$ has exactly one real root great than $1$. Because
$Q'(x) < 0$ for $x \geq 0$ there can ben only one positive root.  Since
$Q(1) = q^d > 0$ and $\lim_{x\rightarrow \infty} Q(x) = -\infty$, $Q$
vanishes for a real number greater than $1$.

Third, we show that this is the root with smallest modulus.  Express the
complex roots of $Q$ as $Re^{i\theta}$. They satisfy the equation

\begin{equation*}
1-pRe^{i\theta}\frac{1-q^dR^de^{id\theta}}{1-qRe^{i\theta}} = 0,
Re^{i\theta} \neq \frac{1}{q}.
\end{equation*}

Multiplying through by $1-qRe^{i\theta}$, we obtain an equation of which
we separate the real and the imaginary parts to obtain

\begin{equation*}
\left\{
\begin{array}{ll}
R \cos (\theta) -1 = pq^dR^{d+1} \cos \left( (d+1) \theta) \right) \\
R \sin (\theta) = pq^dR^{d+1} \sin \left( (d+1) \theta) \right)
\end{array}
\right. Re^{i\theta} \neq \frac{1}{q}.
\end{equation*}

Squaring and summing, we obtain the following equation

\begin{equation*}
R^2 = (pq^dR^{d+1})^2 + 2R \cos(\theta) -1.
\end{equation*}

Since $R > 0$, the solution of this equation is minimal when
$2R\cos(\theta)$ is maximal, \textit{i.e.} when $\theta = 0$. In other
words, the root with smallest modulus is a positive real number. We have
seen above that there exsists exactly one and that it is greater than $1$.
\end{proof}

We now have all the tools to approximate the coefficients of $S(z)$ using
proposition~\ref{th:ass} and thus obtain the approximate probability that
a read contains no seed.

\begin{proposition}
\label{th:p}
The probability that a read of of size $k$ is seedless is
asymptotically equivalent to

\begin{equation*}
\frac{C}{z_1^{k+2}},
\end{equation*}

\noindent
where $z_1$ is the only real positive root of the denominator of $S(z)$,
\textit{i.e.} the root of $1-pz(1+qz+\ldots+(qz)^{d-1})$, and where

\begin{equation}
\label{eq:Cp}
C =\frac{(1-qz_1)^2}{p^2\left( 1 + d(qz_1)^{d+1} - (d+1)(qz_1)^d
\right)}.
\end{equation}
\end{proposition}

\begin{proof}
Apply propositions~\ref{th:ass} and \ref{th:roots}, together with the fact
that for any singularity $z$ we have $1+qz+\ldots+(qz)^{d-1} = 1/pz$.
\end{proof}

We now illustrate proposition~\ref{th:p} with a concrete example
explaining how the calculations are done in practice.

\begin{example}
\label{ex:num1}
Let us approximate the probability that a read of size $k=100$ is seedless
for $d=17$ and for a substitution rate $p=0.1$. To find the dominant
singularity of $S$, we need to solve
$1-0.1z\times(1+0.9z+\ldots+(0.9z)^{16}) = 0$.  We rewrite the equation as
$1 - 0.1z\times(1-(0.9 z)^{17})/(1-0.9z) = 0$ and use bisection to solve
it numerically, yielding $z_1 \approx 1.0268856$. Substituting this value
in (\ref{eq:Cp}) yields $C \approx 1.433681$, so the probability that a
read contains no seed is approximately $1.433681 / 1.0268856^{102} \approx
0.095763$. For comparison, a 99\% confidence interval obtained by
performing 10 billion random simulations is $0.09575-0.09577$.
% The magic number is 957598614 out of 10 billion.
\end{example}

\begin{figure}[h]
\centering
\includegraphics[scale=0.445]{simulp.pdf}
\caption{\textbf{Example estimates for substitutions only}. The analytic
combinatorics estimates of proposition~\ref{th:p} are benchmarked against
random simulations. Shown on both panels are the probablities that a read
of given size contains a seed, either estimated by 10,000,000 random
simulations (dots), or by the method described above (lines). The curves
are drawn for $d=17$ and $p=0.08$, $p=0.10$ or $p=0.12$ (from top to
bottom). The difference never exceeds 0.0003 on the examples shown here,
which is the expected variation for this number of random trials.}
\label{fig:simulp}
\end{figure}

Overall, the analytic combinatorics estimates are close to the exact
values. Figure~\ref{fig:simulp} also shows that relatively small changes
in the prboability of error have a large influence on the probability of
that the read contains a seed in the depicted range of read sizes.



%%%%%%%%%%%%%%%%% Subsitutions and deletions %%%%%%%%%%%%%%%%%%

\subsection{Substitutions and deletions}
\label{sec:deletions}

The uniform substitution model does not describe all sequencing
technologies. For instance, long read technologies often have bursts of
insertions and deletions, with typical frequencies that differ from
substitutions. In order to model more complex behaviors, we need to
distinguish the different types of errors.

To not jump too fast into the problem, we will first focus on the
somewhat unrealistic case where errors can be deletions or
susbtitutions, but not insertions. As in the case of uniform
substitutions, we assume that every call is false with a probability $p$
and true with a probability $1-p=q$. But here, we also assume the
``space''  between consecutive nucleotides can contain a deletion with
probability $\delta$.

A deletion adjacent to a substitution is irrelevant because it does not
modify the error-free intervals in any way, but it interrupts an
error-free interval when located between two correct calls. For this
reason, we simplify the problem without loss of generality and assume that
deletions exist only between correct calls. Figure~\ref{fig:deletions}
shows the transition probabilities between errors and correct calls.

\begin{figure}[h]
\centering
\includegraphics[scale=0.9]{deletions.pdf}
\caption{\textbf{Substitutions and deletions}. 
Substitution and deletion rates $\delta$ and $p$ are assumed to be
constant throughout the read. Deletions do not have a state of their own
because they have size $0$ and never ``appear'' in the structure of the
read. Deletions before or after a substitution are ignored because they
have no effect on the error-free intervals. For instance, the transition
from ``Match'' to ``Substitution'' is $\delta p + (1-\delta)p = p$. The
same holds for the other transitions to and from ``Substitution''.}
\label{fig:deletions}
\end{figure}

The weighted generating function of error-free intervals of size $1$ is
simply $qz$. They are either at the beginning of the read or after a
substitution and in both cases deletions are irrelevant. For an error-free
interval of size $k$, we must ensure that there is no deletion in the
$k-1$ ``spaces'' between the nucleotide calls, so the weighted generating
function is $(1-\delta)^{k-1}(qz)^k$. Summing for all the possible sizes,
we obtain the weighted generating function of error-free intervals as

\begin{equation}
\label{eq:Fdel}
F(z) = qz + (1-\delta)(qz)^2 + (1-\delta)^2(qz)^3 \ldots =
\frac{qz}{1-(1-\delta)qz}.
\end{equation}

The only difference with the transwer matrix of
section~\ref{sec:substitutions} is that an error-free interval can follow
another error-free interval, provided there is a deletion between them.
Since the weight of this deletion is $\delta$, the transfer matrix is

\begin{equation*}
M(z) = \left(
\begin{matrix}
\delta F(z) & pz \\
F(z)        & pz
\end{matrix}
\right).
\end{equation*}

To apply proposition~\ref{th:TM2WGF} we need to invert $I-M(z)$, which is
straightforward for a $2 \times 2$ matrix. We obtain

\begin{equation*}
M_*(z) = (I-M(z))^{-1}=
\frac{1}{\lambda(z)}
\left(
\begin{matrix}
1-pz  & pz              \\
F(z) & 1 -\delta F(z)
\end{matrix}
\right),
\end{equation*}

\noindent
where $\lambda(z) = 1-pz-(pz(1-\delta)+\delta)F(z)$ is the determinant of
$I-M(z)$.

As in section~\ref{sec:substitutions}, the row vector $U(z)$ of starting
states is $(F(z), pz)$, and the column vector of end states is $(1,1)$, so
we obtain the weighted generating function of reads as

\begin{equation}
\label{eq:Sdel}
\begin{split}
S(z) &= 1 + U(z) \cdot M_*(z) \cdot V \\
&= \frac{1+(1-\delta)F(z)} {1-pz - \big(pz(1-\delta) + \delta\big)F(z)}
= \frac{1}{1-z}.
\end{split}
\end{equation}

The terms of equation (\ref{eq:Sdel}) cancel out when $F$ is defined as
(\ref{eq:Fdel}). The result is $1/(1-z) = 1+z +z^2 + \ldots$, which means
that the total weight of reads of size $k$ is equal to $1$ for every $k
\geq 0$.

To find the weighted generating function of seedless reads, we need to
limit error-free intervals to a maximum size of $d-1$, \textit{i.e.} to
replace $F(z)$ by its truncation $F_d(z) = qz + (1-\delta)(qz)^2 + \ldots
+ (1-\delta)^{d-2}(qz)^{d-1}$. With this definition, the weighted
generating function of seedless reads is

\begin{equation}
\label{eq:Sdel}
R(z) = \frac{1+(1-\delta)F_d(z)}
  {1-pz - \big(pz(1-\delta) + \delta\big)F_d(z)}.
\end{equation}

Applying proposition~\ref{th:ass} to this expression, we obtain the
following proposition.

\begin{proposition}
\label{th:pd}
The probability that a read of size $k$ is seedless is asymptotically
equivalent to

\begin{equation*}
\frac{C}{z_1^k},
\end{equation*}

\noindent
where $z_1$ is the only real positive root of the denominator of $S(z)$,
\textit{i.e.} the root of $1-pz - \big(pz(1-\delta) +
\delta\big)\big(qz+(1-\delta)(qz)^2 + \ldots +
(1-\delta)^{d-2}(qz)^{d-1}\big)$, and

\begin{equation}
\label{eq:Cpd}
\begin{split}
C &=
\frac{ \big(1-(1-\delta)(1-p)z_1\big)^2 }
{ \big((p+q\delta)z_1  -\gamma^*(1-\delta)^{d-1}(qz_1)^d \big)
\big(\delta+(1-\delta)pz_1\big) }, \\
\gamma^* &= d\delta -(1-\delta)\big((d-1)\delta-p((d-1)\delta+d+1)\big)z_1
- d(1-\delta)^2pqz_1^2.
\end{split}
\end{equation}
\end{proposition}

\begin{remark}
Notice that the power of $z_1$ differs between propositions~\ref{th:p} and
\ref{th:pd}. The reason is that the factors $z$ or $1/z$ have been moved
out of the constant $C$ in expressions (\ref{eq:Cp}) and (\ref{eq:Cpd}).
\end{remark}

\begin{example}
\label{ex:num2}
Let us approximate the probablity that a read of size $k = 100$ is
seedless for $d=17$, $p = 0.05$ and $\delta = 0.15$, respectively.
In order to find the dominant singularity of $S$ expressed as
(\ref{eq:Sdel}), we need to solve the equation $1-0.05z - \big(0.0425z +
0.15\big) \big(0.95z+0.85(0.95z)^2 + \ldots + 0.85^{15}(0.95z)^{16}\big) =
0$. We write it as $1-0.05z - \big(0.0425z + 0.15)
(0.95z-0.85^{16}(0.95z)^{17}) / (1-0.8075z) = 0$ and use bisection to
solve it, yielding $z_1 \approx 1.006705$. Now substituting the obtained
value in (\ref{eq:Cpd}) gives $C \approx 1.088876$, so the probability
that a read contains no seed is approximately $1.088876 / 1.006705^{100}
\approx 0.558141$. For comparison, a 99\% confidence interval obtained by
performing 10 billion random simulations is $0.55813-0.55816$.
% The magic number is 5581417733 out of 10 billion.
\end{example}

\begin{figure}[h]
\centering
\includegraphics[scale=0.445]{simulpdel.pdf}
\caption{\textbf{Example estimates for substitutions and deletions}. The
analytic combinatorics estimates of proposition~\ref{th:pd} are
benchmarked against random simulations. Shown on both panels are the
probablities that a read of given size contains a seed, either estimated
by 10,000,000 random simulations (dots), or by the method described above
(lines). The curves are drawn for $d=17$, $p=0.05$ and $\delta=0.14$,
$\delta=0.15$ or $\delta=0.16$ (from top to bottom). The difference never
exceeds 0.0003 on the examples shown here, which is the expected variation
for this number of random trials.}
\label{fig:simulpdel}
\end{figure}




%%%%%%%%%%% Subsitutions, deletions and insertions %%%%%%%%%%%%

\subsection{Substitutions, deletions and insertions}
\label{subsec:sdi}

Introducing insertions brings two additional difficulties. The first is
that substitution is indistinguishable from an insertion followed by a
deletion (or a deletion followed by an insertion). By convention, we will
count all these cases as substitutions. This entails that a deletion can
never be found next to an insertion. The second difficulty is that
insertions usually come in bursts. This is also the case of deletions, but
we could neglect it because this does not affect the size of the interval
(all deletions have size $0$). 

We still denote the probability of substitution as $p$ and the probability
of deletion $\delta$. To model insertion bursts, we need to assign a
probability $r$ to the first insertion, and a probability $\tilde{r} > r$
to all subsequent insertions of the burst. We will still denote the
probability of a correct call as $q$, but here $q = 1-p-r$.  An insertion
burst stops with probability $1-\tilde{r}$ at each position, sandt is
followed by either a match or a substitution with probability $1-p/(1-r) =
q/(1-r)$ and $p/(1-r)$, respectively. Figure~\ref{fig:insertions} shows
the transition probabilities between matches, substitutions and
insertions.

\begin{figure}[h]
\centering
\includegraphics[scale=0.9]{insertions.pdf}
\caption{\textbf{Substitutions, deletions and insertions}. Rates of
substitution ($p$), deletion ($\delta$) and insertion ($r$) are assumed to
be contant throughout the read. The prolongation rate of insertions
($\tilde{r}$) is also assumed to be constant. Here $q = 1-p-r$ and the
transitions from ``Inertion'' to ``Match'' and ``Substitution'' are
normalized to maintain a constant rate of substitution.}
\label{fig:insertions}
\end{figure}

As in section\ref{sec:deletions}, we must ensure that there is no deletion
between any two positions of an error-free interval. The weighted
generating function thus comes as

\begin{equation*}
F(z) = qz + (1-\delta)(qz)^2 + (1-\delta)^2(qz)^3 \ldots =
\frac{qz}{1-(1-\delta)qz}.
\end{equation*}

This expression is the same as in the case of section\ref{sec:deletions},
but here $q = 1-p-r$ instead of $1-p$. Based on the error model and the
conventions, the transfer matrix for the states ``match'',
``substitution'' and ``insertion'' is

\begin{equation*}
M(z) = \left(
\begin{matrix}
\delta F(z) & pz      & rz  \\
F(z)        & pz      & rz  \\
\frac{1-\tilde{r}}{1-r}F(z)   & \frac{1-\tilde{r}}{1-r}pz & \tilde{r}z
\end{matrix}
\right).
\end{equation*}

The expression of $M_*(z) = (I-M(z))^{-1}$ is omitted because it is
cumbersome and all we need is the value if $1+U(z)\cdot M_*(z)\cdot V$.
We still give the determinant of $I-M(z)$ in full because this will be the
denomiator of the final expression. Up to a factor $1-r$, it is equal to
$1-a(z)-b(z)F(z)$, where

\begin{gather}
\label{eq:a+b}
a(z) = r-\big((p+\tilde{r})r-\tilde{r}-p\big)z
- p(\tilde{r}-r)z^2\text{, and} \\
b(z) = \delta(1-r) - \big((\tilde{r}\delta-(1-\delta)p)(1-r)
-(1-\tilde{r})r\big)z -(1-\delta)p(\tilde{r}-r)z^2.
\notag
\end{gather}

Applying proposition~\ref{th:TM2WGF} the weighted generating function of
reads appears as

\begin{equation}
\label{eq:Rindel}
\begin{split}
R(z) &= 1 + U(z) \cdot M_*(z) \cdot V \\
&= \frac{(1-r)\big( 1-(\tilde{r}-r)z \big)
\left(1+(1-\delta)F(z) \right)}{1-a(z)-b(z)F(z)}
= \frac{1}{1-z}.
\end{split}
\end{equation}

Again, the terms cancel out and we obtain the simple expression
$1/(1-z)$ where all the coefficients are equal to $1$. To find the
weighted generating function of seedless reads, we replace $F(z)$ in
expression (\ref{eq:Rindel}) by its truncated version

\begin{equation*}
\begin{split}
F_d(z) &= qz + (1-\delta)(qz)^2 + (1-\delta)^2(qz)^3 \ldots +
(1-\delta)^{d-2}(qz)^{d-1} \\
&= \frac{qz-(1-\delta)^{d-1}(qz)^d}{1-(1-\delta)qz}.
\end{split}
\end{equation*}

We obtain the following expression

\begin{equation}
\label{eq:Sindel}
S(z) = \frac{(1-r)\big( 1-(\tilde{r}-r)z \big) \left(1+(1-\delta)F_d(z)
\right)}{1-a(z)-b(z)F_d(z)},
\end{equation}

\noindent
where the terms $a(z)$ and $b(z)$ are defined in (\ref{eq:a+b}).

\begin{proposition}
\label{th:pins}
The probability that a read of size $k$ is seedless is asymptotically
equivalent to

\begin{equation*}
\frac{C}{z_1^{k+1}},
\end{equation*}

\noindent
where $z_1$ is the only real positive root of the polynomial
$1-a(z)-b(z)F_d(z) = 1-a(z)-b(z)\big(qz+(1-\delta)(qz)^2 + \ldots +
(1-\delta)^{d-2}(qz)^{d-1}\big)$, and $C = \alpha / \beta$, with

\begin{equation*}
\alpha = (1-r)(1-(\tilde{r}-r)z_1)
   \frac{1-\big((1-\delta)(qz)\big)^d}{1-(1-\delta)qz}
\end{equation*}

\noindent
and
\begin{equation*}
\begin{split}
\beta = a'(z_1) &- \left( b'(z_1) +
\frac{(1-\delta)q}{1-(1-\delta)qz}\right)
\frac{qz-(1-\delta)^{d-1}(qz)^d}{1-(1-\delta)qz} \\
&+b(z_1) \frac{q-d(1-\delta)^{d-1}q^dz^{d-1}}{1-(1-\delta)qz}.
\end{split}
\end{equation*}
\end{proposition}

Note that the constant $C$ above has an explicit expression for a given
value of $z_1$, but it is relatively cumbersome, so it is more useful to
show how to compute it. We now show how to apply propostion~\ref{th:pins} in a
practical case.

\begin{example}
\label{ex:num3}
Let us approximate the probability that a read of size $k=100$ is seedless
for $d=17$ for $p=0.05$, $\delta=0.15$, $r=0.05$ and $\tilde{r}=0.45$.
With these values, $a(z) = 0.05 +0.475z -0.02z^2$ and $b(z) = 0.1425 +
0.00375z-0.017z^2$. We need to solve $0.95-0.475z+0.02z^2 - (0.1425
+0.00375z-0.017z^2)(0.9z+0.85(0.9z)^2+\ldots+0.85^{15}(0.9z)^{16}) = 0$.
We rewrite the equation as $0.95-0.475z+0.02z^2 - (0.1425
+0.00375z-0.017z^2)(0.9z-0.85^{15}(0.9z)^{16})/(1-0.765z) = 0$ and use
bisection to solve it numerically, yielding $z_1 \approx 1.00295617$.
Using proposition~\ref{th:pins}, we obtain $C \approx 1.042504$, so the
probability that a read contains no seed is approximately $1.042504 /
1.00295617^{101} \approx 0.773749$. For comparison, a 99\% confidence
interval obtained by performing 10 billion random simulations is
$0.77373-0.77376$.
% The magic number is 7737489777 out of 10 billion.
\end{example}

\begin{figure}[h]
\centering
\includegraphics[scale=0.445]{simulpins.pdf}
\label{fig:simulpins}
\caption{\textbf{Example estimates for substitutions, deletions and
insertions}. The analytic combinatorics estimates of
proposition~\ref{th:pins} are benchmarked against random simulations.
Shown on both panels are the probablities that a read of given size
contains a seed, either estimated by 10,000,000 random simulations (dots),
or by the method described above (lines). The curves are drawn for $d=17$,
$p=0.05$, $\delta=0.15$, $\tilde{r} = 0.45$ and $r=0.04$, $r=0.05$ or
$r=0.06$ (from top to bottom). The difference never exceeds 0.0002 on the
examples shown here, which is the expected variation for this number of
random trials.}
\end{figure}


\begin{remark}
Note that when $r = \tilde{r} = 0$, $a(z) = pz$ and $b(z) = pz(1-\delta) +
\delta$, so expression (\ref{eq:Sindel}) becomes

\begin{equation*}
S(z) = \frac{1 + (1-\delta)F_d(z)}{1-pz-(pz(1-\delta)+\delta))F_d(z)}.
\end{equation*}

This is expression (\ref{eq:Sdel}), \textit{i.e.} the model described in
section~\ref{sec:deletions}. When we also have $\delta = 0$, this
expression further simplifies to

\begin{equation*}
S(z) = \frac{1 + F_d(z)}{1-pz(1 + F_d(z))}.
\end{equation*}

This is expression (\ref{eq:Sp}), \textit{i.e.} the model described in
section~\ref{sec:substitutions}. In other words, the error models
described previously are special cases of this one.
\end{remark}



%%%%%%%%%%%%%%%%%%%% Empirical error models %%%%%%%%%%%%%%%%%%

\subsection{Empirical error models}
\label{subsec:empirical}

In the theory developed here, the only variable of interest is the
probability distribution of the error intervals. Indeed, the only reason
we introduced different kinds of errors is because they have different
probabilities and different sizes, but the nature of the error is
irrelevant.

In addition to error-free intervlas, we introduce error-only intervals,
which will encapsulate the available information about the size of error
patches. As we will see below, we need to keep error-free intervals and
deletions separate, so error-only intervals are always considered to be
nonempty.

\begin{definition}
\label{def:error-interval}
An error-only interval is a nonempty sequence of errors that cannot be
extended left or right.
\end{definition}

If we have empirical probabilities $p_0, p_1, \ldots, p_n$ such that $p_k$
is the probability that the error pach has size $k$, we can directly write
the weighted generating function of nonempty error intervals as $E(z) =
p_1z + p_2z^2 + \ldots + p_nz^n$. If the terms are estimated by averaging
observations, this function is a polynomial and $n$ is the size of largest
observed error patch.

The weighted generating function of deletions is simply $p_0$. We will set
$\delta = p_0$ for consistency with the previous sections. We need to keep
deletions separate from error-only intervals because a read cannot start
or end with a deletion (there is no way to detect them before the read
starts or after it finishes). For this reason, we must keep one extra
state of the transfer matrix for deletions. But we must remember that an
uninterrupted error patch was either a deletion or an error-only interval,
so deletions and error-free intervals cannot lie next to each other.

An error-free interval can be followed by an error-only interval or by a
deletion, but it cannot be followed by another error-free interval. An
error-only interval can only be followed by an error-free interval.
Similarly, a deletion can only be followed by an error-free inerval. The
transfer matrix of the objects ``error-free interval'', ``error-only
interval'' and ``deletion'' is

\begin{equation*}
M(z) = \left(
\begin{matrix}
0    & E(z) & \delta  \\
F(z) & 0    & 0       \\
F(z) & 0    & 0
\end{matrix}
\right).
\end{equation*}

Since the sequence may neither start nor end with a deletion, the row
vector of start objects $U(z)$ is equal to $(F(z), E(z), 0)$ and the
column vector $V$ of end objects is equal to $(1,1,0)$. The weighted
generating function of reads can be expressed in general terms as

\begin{equation}
\label{eq:Remp_gen}
R(z) = 1 + U(z) \cdot (I-M(z))^{-1} \cdot V =
\frac{\big(1+(1-\delta)F(z)\big)\big(1+E(z)\big)}
   {1-F(z)\big(\delta+E(z)\big)}.
\end{equation}

As previously, the weighted generating function of error-free intervals is
$F(z) = qz + (1-\delta)(qz)^2 + (1-\delta)^2(qz)^3 + \ldots =
qz/(1-(1-\delta)qz)$. Substituting this value in the equation above, we
obtain

\begin{equation}
\label{eq:Remp}
R(z) = \frac{1+E(z)}{1-qz\big(1+E(z)\big)}.
\end{equation}

Epxression (\ref{eq:Remp}) is not equal to $1/(1-z)$ because $E(z)$ is in
general not equal to $pz/(1-pz)$. This means that the total weight of
reads of size $k$ is not equal to $1$, so we will need to take this
into account in our approximations. As usual, we will use
proposition~\ref{th:ass}, implying that we have to find the root with
smallest modulus of the polynomial $1-qz\big(1+E(z)\big)$.

To find the weighted generating function of seedless reads, we need to
replace $F(z)$ by its truncation $F_d(z) = qz + (1-\delta)(qz)^2 + \ldots
+ (1-\delta)^{d-2}(qz)^{d-1}$ in expression (\ref{eq:Remp_gen}). The terms
only partially cancel each other and we obtain

\begin{equation}
\label{eq:Semp}
S(z) = \frac{\big(1+E(z)\big)\big( 1-(1-\delta)^d(qz)^d \big)}
{1-(1-\delta)qz-qz\big(1-(1-\delta)^{d-1}(qz)^{d-1}\big)
\big(\delta+E(z)\big) }.
\end{equation}

To estimate the total weight of seedless reads, we need to find the root
with smallest modulus of $1-qz\big(1+E(z)\big) +
(1-\delta)^{d-1}(qz)^{d-1}\big(\delta+E(z)\big)$. The solution depends on
the particular expression of $E(z)$. Even though the process can be
automated using proposition~\ref{th:ass}, every case is different and
we cannot give an explicit formula here.

\begin{example}
Assume that a series of empirical measurements suggest that $q = 0.9$,
$\delta = 0.1$ and that error patches have size $1$, $2$ or $3$ have
probabilities $0.5$, $0.33$ and $0.17$. This implies that $E(z) = 0.5z +
0.33z^2+0.17z^3$.

If we choose seeds of size $d=17$, the weighted generating function of
reads show in (\ref{eq:Remp}) becomes

\begin{equation*}
R(z) = \frac{1+0.5z +0.33z^2+0.17z^3}
{1-0.9z\big(1+0.5z +0.33z^2+0.17z^3\big)}.
\end{equation*}

The smallest root of the denominator is approximately equal to $0.1946949$
and applying proposition~\ref{th:ass}, the multiplicative constant is
approximately equal to $1.905695$, so the total weight of reads of size
$k$ is approximately equal to $1.905695/0.1946949^{k+1}$.

Similary, the weighted generating function of seedless reads shown in
(\ref{eq:Semp}) becomes

\begin{equation*}
S(z) = \frac{\big(1+0.5z +0.33z^2+0.17z^3\big)\big( 1-(0.81z)^{17} \big)}
{1-0.81z-0.9z(1-(0.81z)^{16})(0.1+0.5z +0.33z^2+0.17z^3)}.
\end{equation*}

The smallest root of the denominator is approximately $0.0122100$ and the
ultiplicative constant is approximately equal to $0.0135667$. So the total
weight of seedless reads of size $k$ is approximately equal to $0.0135667
/ 0.0122100^{k+1}$.

Combining these two results, we obtain the probability that a read of size
$k$ has no seed as the ratio of the total weights computed above. This is
approximately equal to $0.007119 / 0.06271356^{k+1}$.
\end{example}
















%%%%%%%%%%%%%%%%%% Inexact seeding %%%%%%%%%%%%%%%%%%%%%
\section{Inexact seeding}

We now consider a more challenging problem. The ongoing development of
algorithms and data structures makes it possible to search inexact seeds,
\textit{i.e.} sequences that are very similar but not identical to the
target. This comes at greater cost than finding exactly similar sequences,
but it may be worth it because the chances are higher to identify the
target. By tolerating errors in the seed, one can look for longer seeds,
which also reduces the false positive rate.

Before showing how to compute the probabilities that a read contains
an inexact seed, let us roll back to the simplest error model that we have
see so far, namely substitutions only. Figure~\ref{fig:sketchinexact}
illustrates graphically the relationship between intervals, substitutions
and seeds.

\begin{figure}[h]
\centering
\includegraphics[scale=0.88]{sketch_inexact_seeding.pdf}
\caption{\textbf{Inexact seeding}. Substitutions (black squares) occur
uniformly at random within the read. They delimit error-free intervals.
Inexact seeds (arrows) are the longest stretches of the read that contain
at most one sbustituttion.}
\label{fig:sketchinexact}

\end{figure}
\begin{definition}
\label{def:seed}
An inexact $d$-seed is an interval of size at least $d$ that contains at
most a bustitution and no other error.
\end{definition}

In other words, an inexact seed is either an error-free interval of size
at least $d$, or the concatenation of two error-free intervals and a
substitution, with total size at least $d$. An exact $d$-seed is an
inexact $d$-seed, but the converse is not true. In this section, a
``seedless'' read will designate a read that does not contain any inexact
seed.

As in the case of exact seeding, we will give a construction of seedless
reads, find the corresponding weighted generating function and extract the
asymptotic behavior of the coefficients. Transfer matrices will come in
handy to express the dependence between the error-free intervals on either
side of a substitution. Because the read is seedless, the sum of the sizes
of the intervals on the left hand side and on the right hand side must not
exceed $d-2$ (the substitution adds $1$ to the size of the seed).

In other words, an error-free interval of size $k$ can be followed by an
error-free interval of size $0$, or size $1$, or size $2$, \ldots, or size
$d-k-2$. These intervals have respective weighted generating function $1$,
$qz$, $(qz)^2$, \ldots, $(qz)^{d-k-2}$, so the transfer matrix is

\begin{equation}
M(z) = pz\left[
\begin{matrix}
1 & qz  & (qz)^2 & (qz)^3 & \ldots & (qz)^{d-3} & (qz)^{d-2} \\
1 & qz  & (qz)^2 & (qz)^3 & \ldots & (qz)^{d-3} & 0          \\
1 & qz  & (qz)^2 & (qz)^3 & \ldots & 0          & 0          \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
1 & qz  & (qz)^2 & 0      & \ldots & 0          & 0          \\
1 & qz  & 0      & 0      & \ldots & 0          & 0          \\
1 & 0   & 0      & 0      & \ldots & 0          & 0
\end{matrix}
\right].
\end{equation}

Note that all the terms are multiplied by $pz$ because we have to prepend
a substitutoin, with weighted generating function $pz$.

Since the sequence may start with an error-only interval of any size from
$0$ to $d-2$, the vector of starting ojects $U(z)$ is $(1, qz, (qz)^2,
\ldots, (qz)^{d-2})$, and because the same holds for the end of the
squence, the vector of end state $V$ is $(1,1, \ldots, 1)^T$.

By proposition~\ref{th:TM2WGF}, the weighted generating function of
seedless reads can be computed as $1+U(z) \cdot (I-M(z))^{-1} \cdot V$.
This expression is not easy to evaluate for large matrices, but it can be
pre-computed for a useful range of values of $d$. The solution can always
be expressed as the ratio of two polynomials, and even though their degree
is high, the asymptotics can be found easily by numerical approaches.

\begin{example}
Let us revisit example~\ref{ex:num1}, where we approximated the
probability that a read of size $k=100$ is seedless for $d=17$ and for a
substitution rate $p=0.1$; but this time we allow the seed to contain one
substitution.  The matrix $M(z)$ is $16\times16$ and the weighted
generating function $1+U(z)\cdot(I-M(z))^{-1}\cdot V$ can be written as
$P(z)/Q(z)$, where $P$ is a polynomial of degree 152 and $Q$ is a
polynomial of degree 153.  Using numerical methods to find the root of $Q$
with smallest modulus, we obtain $z_1 \approx 1.079244$. Likewise,
we obtain $-P(z_1)/Q'(z_1) \approx 2.326700$, so the probability
that the read is seedless is approximately
$2.326700/1.079244^{101} \approx 0.0010511$.
For comparison, a 99\% confidence interval obtained by performing 10
billion random simulations is $0.001049-0.001054$.
% The magic number is 1051660 out of 10 billion.
In these conditions, the chances that the read contains an exact seed is
90.4\%, whereas the chances that it contains a seed with one substitution
is 99.9\%.
\end{example}
















%%%%%%%%%%%%%%%%%% Inexact seeding %%%%%%%%%%%%%%%%%%%%%
\section{Caveats and complements}

\subsection{Low error rates}

In case the error rate is low...

\subsection{Other divergence models}

The difference between the sequences does not have to be sequencing
errors, they can also be evolutionary distances.

\subsection{Inexact seeding with more than one error}

This is fucking impossible...






%%%%%%%%%%%%%%%%%% Inexact seeding %%%%%%%%%%%%%%%%%%%%%
\section{Discussion}

Voila.


%---------------------------------------------------------------
%---------------------------------------------------------------

\bibliography{pubmed,extra}
\bibliographystyle{plain}

%----------------------------------------------------------------

\end{document}

%gs -dNoOutputFonts -sDEVICE=pdfwrite -o out.pdf latex.pdf 
